import torch
import argparse
import sys
import os

# í•„ìš”í•œ ëª¨ë“ˆ ì„í¬íŠ¸ (inference_avsr.pyì™€ ê°™ì€ í™˜ê²½ì´ì–´ì•¼ í•¨)
from datamodule.av_dataset import load_video
from datamodule.transforms import VideoTransform
from datamodule.data_module import collate_LLM

# === í…ŒìŠ¤íŠ¸í•  íŒŒì¼ ê²½ë¡œ (ë³¸ì¸ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •) ===
VIDEO_PATH = "tests/swwv9a.mpg" 
# ==============================================

class MockTokenizer:
    """collate_LLMì„ ì†ì´ê¸° ìœ„í•œ ê°€ì§œ í† í¬ë‚˜ì´ì €"""
    def __init__(self):
        self.pad_token_id = 0
        self.bos_token_id = 1
        self.eos_token_id = 2
    def __call__(self, text, **kwargs):
        return {"input_ids": [1, 2]} 

def debug_video_logic():
    print(f"ğŸš€ [Start] Debugging video processing logic for: {VIDEO_PATH}")
    
    # 1. ë¹„ë””ì˜¤ ë¡œë“œ
    try:
        video = load_video(VIDEO_PATH)
        print(f"1. Load Shape: {video.shape} (Time, H, W)")
    except Exception as e:
        print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # 2. Transform ì ìš©
    video_transform = VideoTransform("test")
    video = video_transform(video)
    print(f"2. After Transform: {video.shape}")

    # 3. [ìˆ˜ì •ëœ ë¡œì§] ì±„ë„ ì°¨ì› ì¶”ê°€
    # inference_avsr.pyì— ì¶”ê°€í•œ ë¡œì§ê³¼ ë™ì¼í•´ì•¼ í•¨
    if len(video.shape) == 3:
        print("   -> Adding Channel dim...")
        video = video.unsqueeze(1)
    print(f"3. After Channel Add: {video.shape} (Time, 1, H, W)")

    # 4. ë‹¤ìš´ìƒ˜í”Œë§ (ë¹„ë””ì˜¤ë§Œ í•´ë‹¹)
    downsample_ratio = 2
    video = video[: video.size(0) // downsample_ratio * downsample_ratio]
    print(f"4. After Downsample: {video.shape}")

    # =========================================================
    # ğŸ•µï¸ collate_LLM ì‹œë®¬ë ˆì´ì…˜ (ë°°ì¹˜ ìƒì„±)
    # =========================================================
    
    batch_data = {"video": video, "tokens": ""}
    batch_list = [batch_data]
    
    # ê°€ì§œ í† í¬ë‚˜ì´ì € ì‚¬ìš©
    tokenizer = MockTokenizer()
    
    print("\nğŸ“¦ Running collate_LLM...")
    try:
        batch = collate_LLM(batch_list, tokenizer, modality="video", is_trainval=False)
        video_tensor = batch["video"]
        print(f"5. Batch Shape (Raw): {video_tensor.shape}")
    except Exception as e:
        print(f"âŒ Collate Error: {e}")
        # collateê°€ ì‹¤íŒ¨í•˜ë©´ ìˆ˜ë™ìœ¼ë¡œ stackí•´ì„œ ì‹œë®¬ë ˆì´ì…˜
        video_tensor = torch.stack([video])
        print(f"5. Batch Shape (Simulated): {video_tensor.shape}")

    # =========================================================
    # ğŸš¨ ìµœì¢… ê²€ì¦ (ì°¨ì› êµì • ë¡œì§ í…ŒìŠ¤íŠ¸)
    # =========================================================
    
    print("\nğŸ› ï¸ Testing Fix Logic...")
    
    final_shape = video_tensor.shape
    
    # 6ì°¨ì›ì´ë©´ êµì • í•„ìš”
    if video_tensor.dim() == 6 and video_tensor.shape[1] == 1:
        print(f"âš ï¸ [ISSUE] 6ì°¨ì› ë°ì´í„° ê°ì§€! ({final_shape})")
        print("   -> squeeze(1) ì ìš© ì¤‘...")
        
        # êµì • ìˆ˜í–‰
        video_tensor = video_tensor.squeeze(1)
        print(f"âœ… [FIXED] Final Shape: {video_tensor.shape}")
        
        if video_tensor.dim() == 5:
            print("ğŸ‰ ì„±ê³µ! ì´ì œ ëª¨ë¸ì— ë“¤ì–´ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            print("âŒ ì—¬ì „íˆ ì´ìƒí•©ë‹ˆë‹¤.")
            
    elif video_tensor.dim() == 5:
        print(f"âœ… [PASS] ì´ë¯¸ ì™„ë²½í•œ 5ì°¨ì›ì…ë‹ˆë‹¤. ({final_shape})")
    else:
        print(f"â“ [UNKNOWN] ì˜ˆìƒ ë°–ì˜ ëª¨ì–‘ì…ë‹ˆë‹¤: {final_shape}")

if __name__ == "__main__":
    debug_video_logic()