import os
import argparse
import torch
import jiwer  # WER ê³„ì‚° ë¼ì´ë¸ŒëŸ¬ë¦¬
from tqdm import tqdm
import pandas as pd
import re

# [ì¤‘ìš”] ìš°ë¦¬ê°€ ìµœì í™”í•œ ì¶”ë¡  ì—”ì§„ ê°€ì ¸ì˜¤ê¸°
from inference_avsr import load_model_from_checkpoint, inference_single_file

def parse_eval_args():
    parser = argparse.ArgumentParser(description="GRID Dataset Evaluation Script")
    
    # === í•„ìˆ˜ ê²½ë¡œ ===
    parser.add_argument("--data_dir", type=str, required=True, help="GRID ë°ì´í„°ì…‹(.mpg, .align)ì´ ìˆëŠ” í´ë” ê²½ë¡œ")
    parser.add_argument("--checkpoint", type=str, required=True)
    parser.add_argument("--pretrain_avhubert_enc_video_path", type=str, required=True)
    parser.add_argument("--llm_model", type=str, default="models/Meta-Llama-3.1-8B")
    
    # === ì‹¤í—˜ ì˜µì…˜ ===
    parser.add_argument("--use_uadf", action="store_true", help="UADF ì‚¬ìš© ì—¬ë¶€ (ë¹„êµ ì‹¤í—˜ìš©)")
    parser.add_argument("--output_csv", type=str, default="eval_result.csv", help="ê²°ê³¼ ì €ì¥ íŒŒì¼ëª…")
    
    # === ê³ ì •/ê¸°ë³¸ê°’ (inference_avsr.pyì™€ ë™ì¼í•˜ê²Œ ìœ ì§€) ===
    parser.add_argument("--modality", type=str, default="audiovisual")
    parser.add_argument("--video_path", type=str, default=None) # ë£¨í”„ ëŒë©´ì„œ ë°”ë€œ
    parser.add_argument("--audio_path", type=str, default=None) # ë£¨í”„ ëŒë©´ì„œ ë°”ë€œ
    parser.add_argument("--pretrain_avhubert_enc_audio_path", type=str, default=None)
    parser.add_argument("--pretrain_avhubert_enc_audiovisual_path", type=str, default=None)
    parser.add_argument("--audio_encoder_name", type=str, default="openai/whisper-medium.en")
    parser.add_argument("--downsample-ratio-video", type=int, default=2)
    parser.add_argument("--downsample-ratio-audio", type=int, default=4)
    parser.add_argument("--max-dec-tokens", type=int, default=32)
    parser.add_argument("--num-beams", type=int, default=1)
    parser.add_argument("--use-lora-avhubert", action="store_true")
    parser.add_argument("--single-projector-avhubert", action="store_true")
    parser.add_argument("--grid-resample-audio", action="store_true")
    parser.add_argument("--uadf-fusion-method", type=str, default="uncertainty")
    parser.add_argument("--uadf-temperature", type=float, default=1.0)
    parser.add_argument("--prompt-audio", type=str, default="Transcribe speech to text.")
    parser.add_argument("--prompt-video", type=str, default="Transcribe video to text.")
    parser.add_argument("--prompt-audiovisual", type=str, default="Transcribe speech and video to text.")
    parser.add_argument("--intermediate-size", type=int, default=2048)
    parser.add_argument("--unfrozen-modules", nargs="*", default=["peft_llm"]) 
    parser.add_argument("--add_PETF_LLM", type=str, default="lora")           
    parser.add_argument("--reduction-lora", type=int, default=64)             
    parser.add_argument("--alpha", type=int, default=8)                       
    parser.add_argument("--downsample-ratio-audiovisual", type=int, default=3)
    parser.add_argument("--pretrained-model-path", type=str, default=None)
    parser.add_argument("--use-half-precision", action="store_true")
    parser.add_argument("--low-cpu-mem-usage", action="store_true", default=True)
    parser.add_argument("--load-in-8bit", action="store_true", default=False) 
    parser.add_argument("--cpu-offload", action="store_true")
    
    return parser.parse_args()

def get_ground_truth(align_path):
    """ .align íŒŒì¼ íŒŒì‹±í•˜ì—¬ ì •ë‹µ ë¬¸ì¥ ì¶”ì¶œ """
    words = []
    try:
        with open(align_path, "r", encoding="utf-8") as f:
            for line in f:
                parts = line.strip().split()
                # í¬ë§·: [ì‹œì‘ì‹œê°„] [ëì‹œê°„] [ë‹¨ì–´]
                if len(parts) >= 3:
                    word = parts[2]
                    # sil(ë¬µìŒ), sp(ì§§ì€ ì •ì ) ì œì™¸
                    if word not in ["sil", "sp"]:
                        words.append(word)
        return " ".join(words).lower() # ì†Œë¬¸ì í†µì¼
    except Exception as e:
        print(f"âš ï¸ ì •ë‹µ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ ({align_path}): {e}")
        return ""

def clean_text(text):
    """ íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì†Œë¬¸ì ë³€í™˜ (WER ê³„ì‚°ìš©) """
    text = text.lower()
    text = re.sub(r"[^a-z0-9\s]", "", text) # ì˜ë¬¸, ìˆ«ì, ê³µë°±ë§Œ ë‚¨ê¹€
    return text.strip()

def main():
    args = parse_eval_args()
    
    # 1. ëª¨ë¸ ë¡œë“œ (í•œ ë²ˆë§Œ ìˆ˜í–‰)
    print("ğŸš€ ëª¨ë¸ ë¡œë”© ì¤‘...")
    # ìš°ë¦¬ê°€ ë§Œë“  inference_avsr.pyì˜ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ OOM ê±±ì • ì—†ìŒ!
    model = load_model_from_checkpoint(args.checkpoint, args)
    print("âœ… ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!")

    # 2. íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘ (.mpg íŒŒì¼ ê¸°ì¤€)
    video_files = [f for f in os.listdir(args.data_dir) if f.endswith('.mpg') or f.endswith('.mp4')]
    video_files.sort()
    
    results = []
    total_wer = 0
    count = 0

    print(f"ğŸ“‚ ì´ {len(video_files)}ê°œ íŒŒì¼ í‰ê°€ ì‹œì‘... (UADF ì ìš© ì—¬ë¶€: {args.use_uadf})")

    # 3. í‰ê°€ ë£¨í”„
    for vid_file in tqdm(video_files):
        video_path = os.path.join(args.data_dir, vid_file)
        # .mpg -> .align í™•ì¥ì ë³€ê²½
        align_path = os.path.splitext(video_path)[0] + ".align"
        
        # ì •ë‹µ íŒŒì¼ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if not os.path.exists(align_path):
            continue
            
        ground_truth = get_ground_truth(align_path)
        if not ground_truth: continue # ì •ë‹µ ë‚´ìš©ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ

        # ê²½ë¡œ ì„¤ì • (ì˜¤ë””ì˜¤ëŠ” ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ ì¶”ì¶œ)
        args.video_path = video_path
        args.audio_path = video_path 
        
        try:
            # ì¶”ë¡  ì‹¤í–‰
            prediction = inference_single_file(args, model)
            
            # ì „ì²˜ë¦¬ (ì†Œë¬¸ì, íŠ¹ìˆ˜ë¬¸ì ì œê±°)
            ground_truth_clean = clean_text(ground_truth)
            prediction_clean = clean_text(prediction)
            
            # WER ê³„ì‚°
            wer = jiwer.wer(ground_truth_clean, prediction_clean)
            
            results.append({
                "file": vid_file,
                "ground_truth": ground_truth_clean,
                "prediction": prediction_clean,
                "wer": wer
            })
            
            total_wer += wer
            count += 1
            
        except Exception as e:
            print(f"âŒ Error processing {vid_file}: {e}")

    # 4. ê²°ê³¼ ì§‘ê³„ ë° ì €ì¥
    if count > 0:
        avg_wer = total_wer / count
        print(f"\n{'='*40}")
        print(f"ğŸ“Š ìµœì¢… í‰ê°€ ê²°ê³¼ (UADF: {args.use_uadf})")
        print(f"   - ì´ íŒŒì¼ ìˆ˜: {count}")
        print(f"   - í‰ê·  WER: {avg_wer:.4f} ({avg_wer*100:.2f}%)")
        print(f"{'='*40}")
        
        # CSV ì €ì¥
        df = pd.DataFrame(results)
        df.to_csv(args.output_csv, index=False)
        print(f"ğŸ’¾ ìƒì„¸ ê²°ê³¼ ì €ì¥ë¨: {args.output_csv}")
    else:
        print("âš ï¸ í‰ê°€í•  ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()